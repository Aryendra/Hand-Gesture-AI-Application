{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dlib\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import  time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyautogui as pyg\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data creation\n",
    "# If cleanup is True then the new images and annotations will be appended to previous ones\n",
    "# If False then all previous images and annotations will be deleted.\n",
    "cleanup = False\n",
    "\n",
    "# Set the window to a normal one so we can adjust it\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Resize the window and adjust it to the center\n",
    "# This is done so we're ready for capturing the images.\n",
    "cv2.resizeWindow('frame', 1920,1080)\n",
    "cv2.moveWindow(\"frame\", 0,0)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "\n",
    "# Initalize sliding window's x1,y1\n",
    "x1 ,y1 = 0,0\n",
    "\n",
    "# These will be the width and height of the sliding window.\n",
    "window_width = 190#140  \n",
    "window_height = 190\n",
    "\n",
    "# We will save images after every 4 frames\n",
    "# This is done so we don't have lot's of duplicate images\n",
    "skip_frames = 3\n",
    "frame_gap = 0\n",
    "\n",
    "# This is the directory where our images will be stored\n",
    "# Make sure to change both names if you're saving a different Detector\n",
    "directory = 'train_images_h'\n",
    "box_file = 'boxes_h.txt'\n",
    "\n",
    "# If cleanup is True then delete all imaages and bounding_box annotations.\n",
    "if cleanup:\n",
    "    \n",
    "    # Delete the images directory if it exists\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    \n",
    "    # Clear up all previous bounding boxes\n",
    "    open(box_file, 'w').close()\n",
    "    \n",
    "    # Initialize the counter to 0\n",
    "    counter = 0\n",
    "    \n",
    "elif os.path.exists(box_file):\n",
    "\n",
    "    # If cleanup is false then we must append the new boxes with the old\n",
    "    with open(box_file,'r') as text_file:\n",
    "        box_content = text_file.read()\n",
    "        \n",
    "    # Set the counter to the previous highest checkpoint\n",
    "    counter = int(box_content.split(':')[-2].split(',')[-1])\n",
    "\n",
    "# Open up this text file or create it if it does not exists\n",
    "fr = open(box_file, 'a')\n",
    "\n",
    "# Create our image directory if it does not exists.\n",
    "if not os.path.exists(directory):\n",
    "   os.mkdir(directory)\n",
    "\n",
    "# Initial wait before you start recording each row\n",
    "initial_wait = 0\n",
    "        \n",
    "# Start the loop for the sliding window\n",
    "while(True):\n",
    "    \n",
    "    # Start reading from camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Invert the image laterally to get the mirror reflection.\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "    \n",
    "    # Make a copy of the original frame\n",
    "    orig = frame.copy()    \n",
    "    \n",
    "    # Wait the first 50 frames so that you can place your hand correctly\n",
    "    if initial_wait > 60:\n",
    "        \n",
    "        # Increment frame_gap by 1.\n",
    "        frame_gap +=1  \n",
    "    \n",
    "        # Move the window to the right by some amount in each iteration.    \n",
    "        if x1 + window_width < frame.shape[1]:\n",
    "            x1 += 4\n",
    "            time.sleep(0.1)            \n",
    "            \n",
    "        elif y1 + window_height + 270 < frame.shape[1]:\n",
    "\n",
    "            # If the sliding_window has reached the end of the row then move down by some amount.\n",
    "            # Also start the window from start of the row\n",
    "            y1 += 80    \n",
    "            x1 = 0\n",
    "\n",
    "            # Setting frame_gap and init_wait to 0.\n",
    "            # This is done so that the user has the time to place the hand correctly\n",
    "            # in the next row before image is saved.\n",
    "            frame_gap = 0\n",
    "            initial_wait = 0\n",
    "            \n",
    "        # Break the loop if we have gone over the whole screen.\n",
    "        else:\n",
    "            break\n",
    "              \n",
    "    else: \n",
    "        initial_wait += 1\n",
    "\n",
    "    # Save the image every nth frame.\n",
    "    if frame_gap == skip_frames:\n",
    "\n",
    "        # Set the image name equal to the counter value\n",
    "        img_name = str(counter)  + '.png'\n",
    "\n",
    "        # Save the Image in the defined directory\n",
    "        img_full_name = directory + '/' + str(counter) +  '.png'\n",
    "        cv2.imwrite(img_full_name, orig)\n",
    "        \n",
    "        # Save the bounding box coordinates in the text file.\n",
    "        fr.write('{}:({},{},{},{}),'.format(counter, x1, y1, x1+window_width, y1+window_height))\n",
    "\n",
    "        # Increment the counter \n",
    "        counter += 1\n",
    "\n",
    "        # Set the frame_gap back to 0.\n",
    "        frame_gap = 0\n",
    "\n",
    "    # Draw the sliding window\n",
    "    cv2.rectangle(frame,(x1,y1),(x1+window_width,y1+window_height),(0,255,0),3)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "# Release camera and close the file and window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this dictionary our images and annotations will be stored.**\n",
    "data = {}\n",
    "directory = 'train_images_h'\n",
    "box_file = 'boxes_h.txt'\n",
    "\n",
    "# Get the indexes of all images.\n",
    "image_indexes = [int(img_name.split('.')[0]) for img_name in os.listdir(directory)]\n",
    "\n",
    "# Shuffle the indexes to have random train/test split later on.\n",
    "np.random.shuffle(image_indexes)\n",
    "\n",
    "# Open and read the content of the boxes.txt file\n",
    "f = open(box_file, \"r\")\n",
    "box_content = f.read()\n",
    "\n",
    "# Convert the bounding boxes to dictionary in the format `index: (x1,y1,x2,y2)` ...\n",
    "box_dict =  eval( '{' +box_content + '}' )\n",
    "\n",
    "# Close the file\n",
    "f.close()\n",
    "\n",
    "# Loop over all indexes\n",
    "for index in image_indexes:\n",
    "    \n",
    "    # Read the image in memmory and append it to the list\n",
    "    img = cv2.imread(os.path.join(directory, str(index) + '.png'))    \n",
    "    \n",
    "    # Read the associated bounding_box\n",
    "    bounding_box = box_dict[index]\n",
    "    \n",
    "    # Convert the bounding box to dlib format\n",
    "    x1, y1, x2, y2  = bounding_box\n",
    "    dlib_box = [ dlib.rectangle(left=x1 , top=y1, right=x2, bottom=y2) ]\n",
    "    \n",
    "    # Store the image and the box together\n",
    "    data[index] = (img, dlib_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Images and Boxes Present: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing dta samples **\n",
    "no_of_samples = 20\n",
    "\n",
    "image_names = os.listdir(directory)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Extract the subset of boxes\n",
    "#subset = data[][:no_of_samples ]\n",
    "\n",
    "cols = 5\n",
    "\n",
    "# Given the number of samples to display, what's the number of rows required.\n",
    "rows = int(np.ceil(no_of_samples / cols))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(cols*cols, rows*cols))\n",
    "\n",
    "#Loop for each class\n",
    "for i in range(no_of_samples):\n",
    "        \n",
    "        # Extract the bonding box coordinates\n",
    "        d_box = data[i][1][0]\n",
    "        left, top, right,bottom = d_box.left(), d_box.top(), d_box.right(), d_box.bottom()\n",
    "        \n",
    "        # Get the image\n",
    "        image = data[i][0]\n",
    "        \n",
    "        # Draw reectangle on the detected hand\n",
    "        cv2.rectangle(image,(left,top),(right,bottom),(0,255,0),3)\n",
    "        \n",
    "        # Display the image\n",
    "        plt.subplot(rows,cols,i+1);plt.imshow(image[:,:,::-1]);plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training detector\n",
    "# This is the percentage of data we will use to train\n",
    "# The rest will be used for testing\n",
    "percent = 0.8\n",
    "\n",
    "# How many examples make 80%.\n",
    "split = int(len(data) * percent)\n",
    "\n",
    "# Seperate the images and bounding boxes in different lists.\n",
    "images = [tuple_value[0] for tuple_value in data.values()]\n",
    "bounding_boxes = [tuple_value[1] for tuple_value in data.values()]\n",
    "\n",
    "# Initialize object detector Options\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "\n",
    "# I'm disabling the horizontal flipping, becauase it confuses the detector if you're training on few examples\n",
    "# By doing this the detector will only detect left or right hand (whichever you trained on). \n",
    "options.add_left_right_image_flips = False\n",
    "\n",
    "# Set the c parameter of SVM equal to 5\n",
    "# A bigger C encourages the model to better fit the training data, it can lead to overfitting.\n",
    "# So set an optimal C value via trail and error.\n",
    "options.C = 5\n",
    "\n",
    "# Note the start time before training.\n",
    "st = time.time()\n",
    "\n",
    "# You can start the training now\n",
    "detector = dlib.train_simple_object_detector(images[:split], bounding_boxes[:split], options)\n",
    "\n",
    "# Print the Total time taken to train the detector\n",
    "print('Training Completed, Total Time taken: {:.2f} seconds'.format(time.time() - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Head_Detector.svm'\n",
    "detector.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_det = dlib.image_window()\n",
    "win_det.set_image(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Metrics: {}\".format(dlib.test_simple_object_detector(images[:split], bounding_boxes[:split], detector)))\n",
    "print(\"Testing accuracy: {}\".format(dlib.test_simple_object_detector(images[split:], bounding_boxes[split:], detector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing trained detector**\n",
    "file_name = 'Hand_Detector.svm'\n",
    "\n",
    "# Load our trained detector \n",
    "detector = dlib.simple_object_detector(file_name)\n",
    "\n",
    "# Set the window name\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Setting the downscaling size, for faster detection\n",
    "# If you're not getting any detections then you can set this to 1\n",
    "scale_factor = 2.0\n",
    "\n",
    "# Initially the size of the hand and its center x point will be 0\n",
    "size, center_x = 0,0\n",
    "\n",
    "# Initialize these variables for calculating FPS\n",
    "fps = 0 \n",
    "frame_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the while loop\n",
    "while(True):\n",
    "    \n",
    "    # Read frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Laterally flip the frame\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "    \n",
    "    # Calculate the Average FPS\n",
    "    frame_counter += 1\n",
    "    fps = (frame_counter / (time.time() - start_time))\n",
    "    \n",
    "    # Create a clean copy of the frame\n",
    "    copy = frame.copy()  \n",
    "    \n",
    "    # Downsize the frame.\n",
    "    new_width = int(frame.shape[1]/scale_factor)\n",
    "    new_height = int(frame.shape[0]/scale_factor)\n",
    "    resized_frame = cv2.resize(copy, (new_width, new_height))\n",
    "    \n",
    "    # Detect with detector\n",
    "    detections = detector(resized_frame)\n",
    "    \n",
    "    # Loop for each detection.\n",
    "    for detection in (detections):    \n",
    "        \n",
    "        # Since we downscaled the image we will need to resacle the coordinates according to the original image.\n",
    "        x1 = int(detection.left() * scale_factor )\n",
    "        y1 =  int(detection.top() * scale_factor )\n",
    "        x2 =  int(detection.right() * scale_factor )\n",
    "        y2 =  int(detection.bottom()* scale_factor )\n",
    "        \n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0), 2 )\n",
    "        cv2.putText(frame, 'Hand Detected', (x1, y2+20), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255),2)\n",
    "\n",
    "        # Calculate size of the hand. \n",
    "        size = int( (x2 - x1) * (y2-y1) )\n",
    "        \n",
    "        # Extract the center of the hand on x-axis.\n",
    "        center_x = x2 - x1 // 2\n",
    "    \n",
    "    # Display FPS and size of hand\n",
    "    cv2.putText(frame, 'FPS: {:.2f}'.format(fps), (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255),2)\n",
    "\n",
    "    # This information is useful for when you'll be building hand gesture applications\n",
    "    cv2.putText(frame, 'Center: {}'.format(center_x), (540, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (233, 100, 25))\n",
    "    cv2.putText(frame, 'size: {}'.format(size), (540, 40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (233, 100, 25))\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow('frame',frame)\n",
    "                  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Relase the webcam and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these thresholds accordingly.***\n",
    "\n",
    "# If hand size is larger than this then up, button is triggered\n",
    "size_up_th = 80000\n",
    "\n",
    "# If hand size is smaller than this then down key is triggered\n",
    "size_down_th = 25000\n",
    "\n",
    "# If the center_x location is less than this then left key is triggered\n",
    "left = 160\n",
    "\n",
    "# If the center_x location is greater than this then right key is triggered\n",
    "right = 480\n",
    "\n",
    "# Load our trained detector \n",
    "detector = dlib.simple_object_detector('Hand_Detector.svm')\n",
    "\n",
    "# Set the window to normal\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Setting the downscaling size, for faster detection\n",
    "# If you're not getting any detections then you can set this to 1\n",
    "scale_factor = 2.0\n",
    "\n",
    "# Initially the size of the hand and its center x point will be 0\n",
    "size, center_x = 0,0\n",
    "\n",
    "# Initialize these variables for calculating FPS\n",
    "fps = 0 \n",
    "frame_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the while loop\n",
    "while(True):\n",
    "    \n",
    "    # Read frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Laterally flip the frame\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "    \n",
    "    # Calculate the Average FPS\n",
    "    frame_counter += 1\n",
    "    fps = (frame_counter / (time.time() - start_time))\n",
    "    \n",
    "    # Create a clean copy of the frame\n",
    "    copy = frame.copy()  \n",
    "    \n",
    "    # Downsize the frame.\n",
    "    new_width = int(frame.shape[1]/scale_factor)\n",
    "    new_height = int(frame.shape[0]/scale_factor)\n",
    "    resized_frame = cv2.resize(copy, (new_width, new_height))\n",
    "    \n",
    "    # Detect with detector\n",
    "    detections = detector(resized_frame)\n",
    "    \n",
    "    # Set Default values\n",
    "    text = 'No Hand Detected'\n",
    "    center_x = 0\n",
    "    size = 0\n",
    "\n",
    "    # Loop for each detection.\n",
    "    for detection in (detections):    \n",
    "        \n",
    "        # Since we downscaled the image we will need to resacle the coordinates according to the original image.\n",
    "        x1 = int(detection.left() * scale_factor )\n",
    "        y1 =  int(detection.top() * scale_factor )\n",
    "        x2 =  int(detection.right() * scale_factor )\n",
    "        y2 =  int(detection.bottom()* scale_factor )\n",
    "        \n",
    "        # Calculate size of the hand. \n",
    "        size = int( (x2 - x1) * (y2-y1) )\n",
    "        \n",
    "        # Extract the center of the hand on x-axis.\n",
    "        center_x = int(x1 + (x2 - x1) / 2)\n",
    "        \n",
    "        # Draw the bounding box of the detected hand\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0), 2 )\n",
    "        \n",
    "        # Now based on the size or center_x location set the required text\n",
    "        if center_x > right:\n",
    "            text = 'Right'\n",
    "\n",
    "        elif center_x < left:\n",
    "            text = 'Left'\n",
    "\n",
    "        elif size > size_up_th:\n",
    "            text = 'Up'\n",
    "\n",
    "        elif size < size_down_th:\n",
    "            text = 'Down'\n",
    "            \n",
    "        else:\n",
    "            text = 'Neutral'\n",
    "            \n",
    "    # Now we should draw lines for left/right threshold\n",
    "    cv2.line(frame, (left,0),(left, frame.shape[0]),(25,25,255), 2)\n",
    "    cv2.line(frame, (right,0),(right, frame.shape[0]),(25,25,255), 2)    \n",
    "\n",
    "    # Display Center_x value and size.\n",
    "    cv2.putText(frame, 'Center: {}'.format(center_x), (500, 20), cv2.FONT_HERSHEY_COMPLEX, 0.6, (233, 100, 25), 1)\n",
    "    cv2.putText(frame, 'size: {}'.format(size), (500, 40), cv2.FONT_HERSHEY_COMPLEX, 0.6, (233, 100, 25))\n",
    "\n",
    "    # Finally display the text showing which key should be triggered\n",
    "    cv2.putText(frame, text, (220, 30), cv2.FONT_HERSHEY_COMPLEX, 0.7, (33, 100, 185), 2)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Relase the webcam and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our trained detector \n",
    "detector = dlib.simple_object_detector('Hand_Detector.svm')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Setting the downscaling size, for faster detection\n",
    "# If you're not getting any detections then you can set this to 1\n",
    "scale_factor = 2.0\n",
    "\n",
    "# Initially the size of the hand and its center x point will be 0\n",
    "size, center_x = 0,0\n",
    "\n",
    "# Initialize these variables for calculating FPS\n",
    "fps = 0 \n",
    "frame_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Set Player = True in order to use this script for the VLC video palyer\n",
    "player = True\n",
    "\n",
    "# This variable is True when we press a key and False when there is no detection.\n",
    "# Its only used in the video Player\n",
    "status = False\n",
    "\n",
    "# We're recording the whole screen to view it later\n",
    "screen_width, screen_height = tuple(pyg.size())\n",
    "out = cv2.VideoWriter(r'videorecord.mp4', cv2.VideoWriter_fourcc(*'XVID'), 15.0, (screen_width,screen_height ))\n",
    "\n",
    "# Set the while loop\n",
    "while(True):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # Read frame by frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Laterally flip the frame\n",
    "        frame = cv2.flip( frame, 1 )\n",
    "\n",
    "        # Calculate the Average FPS\n",
    "        frame_counter += 1\n",
    "        fps = (frame_counter / (time.time() - start_time))\n",
    "\n",
    "        # Create a clean copy of the frame\n",
    "        copy = frame.copy()  \n",
    "\n",
    "        # Downsize the frame.\n",
    "        new_width = int(frame.shape[1]/scale_factor)\n",
    "        new_height = int(frame.shape[0]/scale_factor)\n",
    "        resized_frame = cv2.resize(copy, (new_width, new_height))\n",
    "\n",
    "        # Detect with detector\n",
    "        detections = detector(resized_frame)\n",
    "        \n",
    "        # Key will initially be None\n",
    "        key = None\n",
    "\n",
    "        if len(detections) > 0:\n",
    "            \n",
    "            # Grab the first detection\n",
    "            detection = detections[0]\n",
    "\n",
    "            # Since we downscaled the image we will need to resacle the coordinates according to the original image.\n",
    "            x1 = int(detection.left() * scale_factor )\n",
    "            y1 =  int(detection.top() * scale_factor )\n",
    "            x2 =  int(detection.right() * scale_factor )\n",
    "            y2 =  int(detection.bottom()* scale_factor )\n",
    "            \n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0), 2 )\n",
    "            cv2.putText(frame, 'Hand Detected', (x1, y2+20), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255),2)\n",
    "\n",
    "            # Calculate size of the hand. \n",
    "            size = int( (x2 - x1) * (y2-y1) )\n",
    "\n",
    "            # Extract the center of the hand on x-axis.\n",
    "            center_x = int(x1 + (x2 - x1) / 2)\n",
    "\n",
    "            # Press the requird button based on center_x location and size   \n",
    "            # The behaviour of keys will be different depending upon if we're controlling a game or a video player.\n",
    "            # The status variable makes sure we do not double press the key in case of a video player.\n",
    "\n",
    "            if center_x > right:\n",
    "                \n",
    "                key = 'right'\n",
    "                if player and not status:\n",
    "                    pyg.hotkey('ctrl', 'right') \n",
    "                    status = True\n",
    "\n",
    "            elif center_x < left:\n",
    "                \n",
    "                key = 'left'               \n",
    "                if player and not status:\n",
    "                    pyg.hotkey('ctrl', 'left')\n",
    "                    status = True\n",
    "\n",
    "            elif size > size_up_th:\n",
    "                \n",
    "                key = 'up'\n",
    "                if player and not status:\n",
    "                    pyg.press('space')\n",
    "                    status = True\n",
    "\n",
    "            elif size < size_down_th:\n",
    "                key = 'down'\n",
    "            \n",
    "            # Check if we're playing a game then press the requried key\n",
    "            if key is not None and player == False:                \n",
    "                    pyg.press(key)            \n",
    "        \n",
    "        # If there was'nt a detection then status is made False\n",
    "        else:\n",
    "            status = False\n",
    "        \n",
    "        \n",
    "        # Capture the screen\n",
    "        image = pyg.screenshot()\n",
    "        \n",
    "        # Convert to BGR, numpy array (Opencv format of image)\n",
    "        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Resize the camera frame and attach it to screen.\n",
    "        resized_frame = cv2.resize(frame, (0,0), fx=0.6, fy=0.6)\n",
    "        h = resized_frame.shape[0]\n",
    "        w = resized_frame.shape[1]\n",
    "        img[0:h, 0:w]  = resized_frame\n",
    "        \n",
    "        # Save the video frame\n",
    "        out.write(img)\n",
    "        \n",
    "        #time.sleep(0.2)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Releasing the Camera and exiting since the program was stopped')\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the camera and the videowriter if the code above exited from an exception other than KeyboardInterrupt\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
